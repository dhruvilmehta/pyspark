{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler\n","from pyspark.ml import Pipeline\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n","\n","# Creating a Spark session\n","spark = SparkSession.builder.appName(\"example\").getOrCreate()\n","\n","# Reading the CSV file into a DataFrame\n","gcs_file_path = \"gs://vernal-hall-403418/InputData/CrimeData.csv\"\n","df = spark.read.csv(gcs_file_path, header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+------+\n","| Status Desc| count|\n","+------------+------+\n","| Invest Cont|642828|\n","| Adult Other| 86206|\n","|Adult Arrest| 69954|\n","|  Juv Arrest|  2592|\n","|   Juv Other|  1373|\n","|         UNK|     3|\n","+------------+------+\n","\n"]}],"source":["# Grouping the DataFrame by 'Status Desc' and counting occurrences, ordering by count in descending order\n","status_counts = df.groupBy('Status Desc').count().orderBy('count', ascending=False)\n","\n","# Displaying the counts for each 'Status Desc'\n","status_counts.show()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Columns to drop from the DataFrame\n","cols_to_drop = ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Mocodes',\n","                'Premis Cd', 'Weapon Used Cd', 'Status', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Cross Street',\n","                'LAT', 'LON', 'LOCATION']\n","\n","# Dropping specified columns and removing rows with any missing values\n","df = df.drop(*cols_to_drop).na.drop()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Categorical columns to be indexed\n","categorical_cols = ['AREA NAME', 'Crm Cd Desc', 'Vict Sex', 'Vict Descent', 'Premis Desc', 'Weapon Desc']\n","\n","# Creating StringIndexer stages for each categorical column\n","indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\").fit(df) for col in categorical_cols]\n","\n","# Creating a pipeline with the StringIndexer stages\n","pipeline = Pipeline(stages=indexers)\n","\n","# Transforming the DataFrame with the pipeline to add index columns\n","df = pipeline.fit(df).transform(df)\n","\n","# Feature columns for the VectorAssembler\n","feature_cols = ['Vict Age', 'AREA NAME_index', 'Crm Cd Desc_index', 'Vict Sex_index', 'Vict Descent_index',\n","                'Premis Desc_index', 'Weapon Desc_index']"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6310787948597962\n"]}],"source":["# Assembling features using VectorAssembler\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","df = assembler.transform(df)\n","\n","# Indexing the label column using StringIndexer\n","label_indexer = StringIndexer(inputCol=\"Status Desc\", outputCol=\"label\").fit(df)\n","df = label_indexer.transform(df)\n","\n","# Splitting the DataFrame into training and testing sets\n","(training_data, testing_data) = df.randomSplit([0.8, 0.2], seed=42)\n","\n","# Creating a RandomForestClassifier\n","rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", maxBins=500)\n","\n","# Fitting the model on the training data\n","model = rf.fit(training_data)\n","\n","# Making predictions on the testing data\n","predictions = model.transform(testing_data)\n","\n","# Evaluating the accuracy of the model\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","\n","# Printing the accuracy\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Saving the trained model to the specified path in Google Cloud Storage\n","model.save(\"gs://vernal-hall-403418/OutputModel/model\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from pyspark.mllib.evaluation import MulticlassMetrics\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":9,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["DataFrame[Vict Age: bigint, AREA NAME: string, Crm Cd Desc: string, Vict Sex: string, Vict Descent: string, Premis Desc: string, Weapon Desc: string, AREA NAME_index: double, Crm Cd Desc_index: double, Vict Sex_index: double, Vict Descent_index: double, Premis Desc_index: double, Weapon Desc_index: double, features: vector]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Creating a DataFrame with custom input data\n","custom_input_data = [\n","    (71, 'Central', 'ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT', 'M', 'W', 'PUBLIC RESTROOM/OUTSIDE*', 'UNKNOWN WEAPON/OTHER WEAPON')\n","]\n","\n","columns = ['Vict Age', 'AREA NAME', 'Crm Cd Desc', 'Vict Sex', 'Vict Descent', 'Premis Desc', 'Weapon Desc']\n","custom_df = spark.createDataFrame(custom_input_data, columns)\n","\n","# Transforming categorical columns to numerical indices using the previously fitted StringIndexers\n","custom_df = pipeline.fit(df).transform(custom_df)\n","\n","# Assembling features for the custom input data\n","feature_cols = ['Vict Age', 'AREA NAME_index', 'Crm Cd Desc_index', 'Vict Sex_index', 'Vict Descent_index',\n","                'Premis Desc_index', 'Weapon Desc_index']\n","\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","custom_df = assembler.transform(custom_df)\n","\n","# Displaying the DataFrame with features\n","custom_df"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from pyspark.ml.classification import RandomForestClassificationModel\n","model = RandomForestClassificationModel.load(\"gs://vernal-hall-403418/OutputModel/model\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Making predictions using the loaded RandomForestClassificationModel on the custom input data\n","predictions = model.transform(custom_df)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----------+--------------------+\n","|            features|prediction|         probability|\n","+--------------------+----------+--------------------+\n","|[71.0,1.0,1.0,0.0...|       0.0|[0.71800193605307...|\n","+--------------------+----------+--------------------+\n","\n"]}],"source":["# Displaying specific columns from the predictions DataFrame\n","predictions.select(\"features\", \"prediction\", \"probability\").show()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mapping of Status Desc values to encoded values:\n","Invest Cont: 0\n","Adult Other: 1\n","Adult Arrest: 2\n","Juv Arrest: 3\n","Juv Other: 4\n","UNK: 5\n"]}],"source":["# Obtaining the labels used by the StringIndexer for 'Status Desc'\n","status_desc_labels = label_indexer.labels\n","\n","# Displaying the mapping of 'Status Desc' values to encoded values\n","print(\"Mapping of Status Desc values to encoded values:\")\n","for label, encoded_value in enumerate(status_desc_labels):\n","    print(f\"{encoded_value}: {label}\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}